# QuillGuard Backend ğŸª¶ğŸ›¡ï¸

> **ğŸš€ RUST-POWERED AI GRAMMAR ENGINE**  
> âš¡ Zero Python â€¢ ğŸ¤– Real ONNX â€¢ ğŸ›¡ï¸ Type Safe

**QuillGuard's Three-Stage Grammar Correction Backend**

## ğŸ”„ How It Works

```mermaid
graph TD
    A["ğŸ“ INPUT TEXT<br/>i dont beleive its working"] --> B["ğŸ”§ HARPER<br/>Rule-Based Precision<br/>â±ï¸ ~1ms"]
    B --> B1["âœ“ Spelling: dont â†’ don't<br/>âœ“ Spelling: beleive â†’ believe<br/>âœ“ Capitalization: i â†’ I"]
    B1 --> C["I don't believe its working"]
    
    C --> D["ğŸ¤– GRAMFORMER<br/>Grammar Intelligence<br/>â±ï¸ ~100ms"]
    D --> D1["âœ“ Grammar: its â†’ it's<br/>âœ“ Punctuation: added period<br/>âœ“ Sentence structure"]
    D1 --> E["I don't believe it's working."]
    
    E --> F["ğŸ§  FLAN-T5<br/>Semantic Enhancement<br/>â±ï¸ ~2000ms"]
    F --> F1["âœ“ Semantic: added 'properly'<br/>âœ“ Context awareness<br/>âœ“ Natural flow"]
    F1 --> G["âœ¨ I don't believe it's working properly."]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style D fill:#e8f5e8
    style F fill:#fff3e0
    style G fill:#f1f8e9
```

---

### ğŸ¯ Three-Stage Results

| Stage | Input | Key Changes | Output | Time |
|-------|-------|-------------|--------|------|
| ğŸ”§ **Harper** | "i dont beleive its working" | Spelling + Caps | "I don't believe its working" | ~1ms |
| ğŸ¤– **Gramformer** | "I don't believe its working" | Grammar + Punct | "I don't believe it's working." | ~100ms |
| ğŸ§  **FLAN-T5** | "I don't believe it's working." | Semantic Flow | "I don't believe it's working properly." | ~2s |

## ğŸš€ Features

- **âš¡ Pure Rust Performance**: Zero Python dependencies, full ONNX Runtime integration
- **ğŸ¯ Three-Stage Pipeline**: Harper â†’ Gramformer â†’ FLAN-T5 correction stages
- **ğŸ¤– Real AI Inference**: ONNX models with autoregressive text generation
- **ğŸ”§ Production Ready**: Comprehensive error handling and graceful fallbacks
- **ğŸ“Š Transparent Results**: See corrections from each stage individually
- **ğŸ›¡ï¸ Type Safety**: Full Rust type safety with Axum framework

## ğŸš€ Getting Started

### 1. Start the Grammar Backend
```bash
cd lserver
cargo run
```

### 2. Test the Three-Stage API

> **ğŸŒ API TESTING EXAMPLE**

**ğŸ“¤ Send Request:**
```bash
curl -X POST http://localhost:3000/api/grammar \
  -H "Content-Type: application/json" \
  -d '{"text": "i can has cheezburger", "dialect": "American", "use_t5": true}'
```

**ğŸ“¥ Get Response:**
```json
{
  "suggestions": [
    {
      "kind": "three_stage",
      "message": "Three-stage enhancement (Harper â†’ Gramformer â†’ FLAN-T5)",
      "replacements": [
        "I can has cheeseburger",        // ğŸ”§ HARPER
        "I can have cheeseburgers.",     // ğŸ¤– GRAMFORMER  
        "I can have cheeseburgers."      // ğŸ§  FLAN-T5
      ]
    }
  ]
}
```

**ğŸ” Stage-by-Stage Breakdown:**

```
â”Œâ”€ ğŸ”§ HARPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€ ğŸ¤– GRAMFORMER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€ ğŸ§  FLAN-T5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ“ i â†’ I                     â”‚  â”‚ âœ“ has â†’ have               â”‚  â”‚ âœ“ Context preserved        â”‚
â”‚ âœ“ cheezburger â†’             â”‚  â”‚ âœ“ Added period             â”‚  â”‚ âœ“ Grammar validated        â”‚
â”‚   cheeseburger              â”‚  â”‚ âœ“ Pluralization            â”‚  â”‚ âœ“ Natural flow            â”‚
â”‚                             â”‚  â”‚                            â”‚  â”‚                           â”‚
â”‚ "I can has cheeseburger"    â”‚  â”‚ "I can have cheeseburgers."â”‚  â”‚ "I can have cheeseburgers"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Monitor Real-Time Processing
```bash
# Watch the logs to see each stage in action
tail -f lserver.log
```

**ğŸ“Š Log Output:**
```
INFO Harper processing: 'i can has cheezburger'
INFO Gramformer processing: 'I can has cheeseburger'  
INFO FLAN-T5 processing: 'I can have cheeseburgers.'
INFO Three-stage result ready
```

## ğŸ“ Project Architecture

> **ğŸ—ï¸ SYSTEM OVERVIEW**

### ğŸ“‚ Directory Structure

```
lserver/
â”œâ”€â”€ ğŸ“¦ Cargo.toml                    # Dependencies (ort, hf-hub, tokenizers)
â”œâ”€â”€ ğŸš€ src/main.rs                   # Axum server & API routes
â””â”€â”€ ğŸ“‚ src/lang/
    â”œâ”€â”€ ğŸ¯ lint.rs                   # Three-stage pipeline orchestration
    â”œâ”€â”€ ğŸ”§ grammar.rs                # FLAN-T5 ONNX implementation  
    â””â”€â”€ ğŸ›¡ï¸ state.rs                  # Harper rule engine integration

ğŸ“‚ ../gramformer_onnx/               # Gramformer ONNX model (~200MB)
â”œâ”€â”€ ğŸ¤– model.onnx
â””â”€â”€ ğŸ“„ tokenizer.json

ğŸ“‚ ../flan_t5_onnx/                  # FLAN-T5 ONNX model (~1.5GB + 435 files)
â”œâ”€â”€ ğŸ§  model.onnx (1.65MB)
â”œâ”€â”€ ğŸ“„ tokenizer.json (2.4MB)
â””â”€â”€ ğŸ“ 435 weight files (1.5GB)
```

### ğŸ”§ Component Breakdown

| Component | Purpose | Technology | Performance |
|-----------|---------|------------|-------------|
| ğŸ”§ **Harper** | Rule-based fixes | Built-in Rust crate | ~1ms âš¡ |
| ğŸ¤– **Gramformer** | Grammar patterns | ONNX + Custom model | ~100ms ğŸ¤– |
| ğŸ§  **FLAN-T5** | Semantic enhancement | ONNX + HuggingFace | ~2000ms ğŸ§  |
| ğŸ¯ **Pipeline** | Stage orchestration | Pure Rust | Error handling |
| ğŸŒ **API** | HTTP interface | Axum + Serde JSON | Type safety |

### ğŸ”„ Request Flow

```mermaid
sequenceDiagram
    participant Client
    participant API as ğŸŒ Axum API
    participant Pipeline as ğŸ¯ Pipeline
    participant Harper as ğŸ”§ Harper
    participant Gramformer as ğŸ¤– Gramformer
    participant FLAN as ğŸ§  FLAN-T5

    Client->>API: POST /api/grammar
    API->>Pipeline: Process text
    
    Pipeline->>Harper: Stage 1 (~1ms)
    Harper-->>Pipeline: Rule-based fixes
    
    Pipeline->>Gramformer: Stage 2 (~100ms)
    Gramformer-->>Pipeline: Grammar corrections
    
    Pipeline->>FLAN: Stage 3 (~2000ms)
    FLAN-->>Pipeline: Semantic enhancements
    
    Pipeline->>API: Combined results
    API->>Client: JSON response
```

## ğŸ”§ Performance & Configuration

> **âš¡ PERFORMANCE METRICS**

### ğŸ“Š Stage Performance Comparison

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor': '#ff0000'}}}%%
xychart-beta
    title "Performance Comparison by Stage"
    x-axis [Harper, Gramformer, FLAN-T5]
    y-axis "Latency (ms)" 0 --> 2100
    bar [1, 100, 2000]
```

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor': '#00ff00'}}}%%
xychart-beta
    title "Memory Usage by Stage"
    x-axis [Harper, Gramformer, FLAN-T5]
    y-axis "Memory (MB)" 0 --> 3100
    bar [10, 500, 3000]
```

| Metric | ğŸ”§ Harper | ğŸ¤– Gramformer | ğŸ§  FLAN-T5 | ğŸ¯ Total |
|--------|-----------|---------------|-------------|----------|
| **â±ï¸ Latency** | ~1ms âš¡ | ~100ms ğŸ¤– | ~2000ms ğŸ§  | **~2.1s** |
| **ğŸ’¾ Memory** | 10MB ğŸª¶ | 500MB ğŸ“Š | 3GB ğŸ§  | **3.5GB** |
| **ğŸ¯ Accuracy** | 99% (rules) | 85% (patterns) | 70% (semantic) | **Combined** |
| **ğŸ”§ Specialty** | Rules & Spelling | Grammar Patterns | Semantic Flow | **Three-Stage** |

### ğŸ“ˆ Performance Characteristics

**ğŸ”§ Harper (Lightning Fast)**
- âœ… **Speed:** Sub-millisecond response
- âœ… **Memory:** Minimal footprint (10MB)
- âœ… **Accuracy:** Perfect for rule-based corrections (99%)
- ğŸ¯ **Best for:** Spelling, capitalization, basic punctuation

**ğŸ¤– Gramformer (Neural Processing)**
- âœ… **Speed:** Fast neural inference (100ms)
- âœ… **Memory:** Moderate model size (500MB)
- âœ… **Accuracy:** Strong grammar pattern recognition (85%)
- ğŸ¯ **Best for:** Verb tense, subject-verb agreement, sentence structure

**ğŸ§  FLAN-T5 (Deep Thinking)**
- âš ï¸ **Speed:** Slower autoregressive generation (2s)
- âš ï¸ **Memory:** Large language model (3GB)
- âœ… **Accuracy:** Context-aware semantic improvements (70%)
- ğŸ¯ **Best for:** Natural flow, semantic corrections, contextual enhancements

### âš™ï¸ Configuration Options

```rust
// In src/lang/lint.rs - Adjust pipeline behavior
pub struct GrammarConfig {
    pub enable_harper: bool,        // Rule-based corrections
    pub enable_gramformer: bool,    // Grammar intelligence  
    pub enable_flan_t5: bool,       // Semantic enhancement
    pub max_text_length: usize,     // Input length limit
    pub timeout_ms: u64,            // Per-stage timeout
}
```

### ğŸ¯ Adding Custom Rules

Extend Harper rules in `src/lang/state.rs`:

```rust
// Add custom spelling corrections
let mut custom_dict = HashMap::new();
custom_dict.insert("teh", "the");
custom_dict.insert("recieve", "receive");

// Add to Harper configuration
harper_config.with_custom_dictionary(custom_dict);
```

### ğŸš€ Performance Optimization

```rust
// Enable model quantization (reduces memory)
let session = SessionBuilder::new()?
    .with_optimization_level(GraphOptimizationLevel::Level3)?
    .with_inter_op_num_threads(4)?
    .commit_from_file(&model_path)?;
```

## ğŸš§ Future Enhancements

### ğŸ¯ Performance Improvements
- **Model Quantization**: Reduce FLAN-T5 memory usage by 50%
- **Batch Processing**: Process multiple texts simultaneously  
- **Caching**: Cache frequent corrections to reduce latency
- **Streaming**: Real-time corrections as user types

### ğŸ¤– Model Improvements  
- **Fine-tuning**: Domain-specific grammar models
- **Better Fallbacks**: Smarter error handling for FLAN-T5 loops
- **Multi-language**: Support for Spanish, French, German
- **Custom Models**: Train models for specific writing styles

### ğŸ”§ Infrastructure
- **Docker**: Containerized deployment with model preloading
- **Kubernetes**: Scalable deployment with auto-scaling
- **Monitoring**: Prometheus metrics for each stage
- **API Docs**: OpenAPI specification with examples

## ğŸ“š Resources

### ğŸ¤– AI & ML
- [ONNX Runtime Rust](https://ort.pyke.io/) - ONNX inference in Rust
- [HuggingFace Hub](https://huggingface.co/docs/huggingface_hub/index) - Model downloads
- [Tokenizers](https://huggingface.co/docs/tokenizers/index) - Text tokenization

### ğŸ”§ Grammar Tools
- [Harper](https://harper-ls.github.io/) - Rule-based grammar checking
- [FLAN-T5 Model](https://huggingface.co/pszemraj/flan-t5-large-grammar-synthesis) - Grammar synthesis model

### ğŸš€ Rust Web
- [Axum Documentation](https://docs.rs/axum/latest/axum/) - Web framework
- [Tokio Documentation](https://tokio.rs/tokio/tutorial) - Async runtime
- [Serde Documentation](https://serde.rs/) - JSON serialization
